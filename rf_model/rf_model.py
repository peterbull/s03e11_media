# AUTOGENERATED! DO NOT EDIT! File to edit: ../rf_model.ipynb.

# %% auto 0
__all__ = ['comp', 'path', 'df_train', 'df_test', 'df_comb', 'train_idxs', 'test_idxs', 'dep_var', 'procs', 'cont', 'cat',
           'splits', 'to_final', 'test_final', 'dls_final', 'xs', 'y', 'valid_xs', 'valid_y', 'test_xs', 'm',
           'rf_preds', 'rf', 'r_mse', 'm_rmse', 'rf_feat_importance']

# %% ../rf_model.ipynb 1
from fastai.tabular.all import *

from sklearn.model_selection import KFold, train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance


import xgboost as xgb

import seaborn as sns

import optuna

import json

# %% ../rf_model.ipynb 2
try: import fastkaggle
except ModuleNotFoundError:
    !pip install -Uq fastkaggle

from fastkaggle import *

# %% ../rf_model.ipynb 3
comp = 'playground-series-s3e11'
path = setup_comp(comp, install='fastai')

# %% ../rf_model.ipynb 4
df_train = pd.read_csv(path/'train.csv', low_memory=False)
df_test = pd.read_csv(path/'test.csv', low_memory=False)
df_comb = pd.concat([df_train, df_test], ignore_index=True)

# %% ../rf_model.ipynb 5
df_train.drop(['id'], axis=1, inplace=True)
df_test.drop(['id'], axis=1, inplace=True)
df_comb.drop(['id'], axis=1, inplace=True)

# %% ../rf_model.ipynb 6
df_train['store_sales_per_children'] = df_train['store_sales(in millions)'] / df_train['total_children']

# %% ../rf_model.ipynb 7
for column in df_train.columns:
    if (list(df_train[column].unique()) == [0.0, 1.0]):
        df_train.loc[:, column] = df_train[column].astype('bool')

# %% ../rf_model.ipynb 8
train_idxs = np.arange(len(df_train))
test_idxs = np.arange(len(df_train), len(df_comb))

# %% ../rf_model.ipynb 9
dep_var = 'cost'
procs = [Categorify, FillMissing, Normalize]
cont, cat = cont_cat_split(df_comb, max_card=1, dep_var=dep_var)
splits = RandomSplitter(valid_pct=0.2)(range_of(df_train))

# %% ../rf_model.ipynb 10
df_train = df_comb.iloc[train_idxs]
df_test = df_comb.iloc[test_idxs]

# %% ../rf_model.ipynb 11
to_final = TabularPandas(df_train, procs, cat, cont, y_names=dep_var, splits=splits)
test_final = TabularPandas(df_test, procs, cat, cont, y_names=None, splits=None)
dls_final = to_final.dataloaders(bs=1024)

# %% ../rf_model.ipynb 13
xs, y = to_final.train.xs, to_final.train.y
valid_xs, valid_y = to_final.valid.xs, to_final.valid.y
test_xs = test_final.train.xs

# %% ../rf_model.ipynb 14
def rf(xs, y, n_estimators=40, max_samples=200_000, max_features=0.5, min_samples_leaf=5, **kwargs):
    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators, 
                                 max_samples=max_samples, max_features=max_features,
                                 min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)

# %% ../rf_model.ipynb 20
def r_mse(pred, y):
    return round(math.sqrt(((pred-y)**2).mean()), 6)

# %% ../rf_model.ipynb 21
def m_rmse(m, xs, y):
    return r_mse(m.predict(xs), y)

# %% ../rf_model.ipynb 22
m = rf(xs, y, **rf_best_params)

# %% ../rf_model.ipynb 24
rf_preds = m.predict(test_xs)
np.savetxt('./predictions/rf_preds.csv', rf_preds, delimiter=',')

# %% ../rf_model.ipynb 25
rf_preds = np.loadtxt('./predictions/rf_preds.csv', delimiter=',')

# %% ../rf_model.ipynb 27
def rf_feat_importance(m, df):
    return pd.DataFrame({'cols':df.columns, 'imp': m.feature_importances_}).sort_values('imp', ascending=False) 

# %% ../rf_model.ipynb 30
np.savetxt('./predictions/rf_preds.csv', rf_preds, delimiter=',')

# %% ../rf_model.ipynb 31
rf_preds = np.loadtxt('./predictions/rf_preds.csv', delimiter=',')
