{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| defualt_exp nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "comp = 'playground-series-s3e11'\n",
    "path = setup_comp(comp, install='fastai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df_train = pd.read_csv(path/'train.csv', low_memory=False)\n",
    "df_test = pd.read_csv(path/'test.csv', low_memory=False)\n",
    "df_comb = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df_train.drop(['id'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "df_comb.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df_train['store_sales_per_children'] = df_train['store_sales(in millions)'] / df_train['total_children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "for column in df_train.columns:\n",
    "    if (list(df_train[column].unique()) == [0.0, 1.0]):\n",
    "        df_train.loc[:, column] = df_train[column].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "train_idxs = np.arange(len(df_train))\n",
    "test_idxs = np.arange(len(df_train), len(df_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "dep_var = 'cost'\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "cont, cat = cont_cat_split(df_comb, max_card=1, dep_var=dep_var)\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df_train = df_comb.iloc[train_idxs]\n",
    "df_test = df_comb.iloc[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "to_final = TabularPandas(df_train, procs, cat, cont, y_names=dep_var, splits=splits)\n",
    "test_final = TabularPandas(df_test, procs, cat, cont, y_names=None, splits=None)\n",
    "dls_final = to_final.dataloaders(bs=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing NN Parameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nn_trial(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1)\n",
    "    wd = trial.suggest_float('wd', 1e-6, 1e-1)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 100, 1000)\n",
    "    \n",
    "\n",
    "    layer_sizes = [hidden_dim] * n_layers\n",
    "\n",
    "    learn = tabular_learner(dls_final, layers=layer_sizes, metrics=rmse, wd=wd)\n",
    "    learn.fit_one_cycle(10, lr)\n",
    "\n",
    "    # Return the validation loss (or any other metric of your choice)\n",
    "    return learn.recorder.values[-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nn_study = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if nn_study == True:\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(nn_trial, n_trials=50)\n",
    "    with open('./training_params/nn_params.json', 'w') as fp:\n",
    "        json.dump(study.best_params, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open('./training_params/nn_params.json', 'r') as fp:\n",
    "    nn_best_params = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028868944455163"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "nn_lr = nn_best_params['lr']\n",
    "nn_best_params.pop('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "nn_best_params['layers'] = [nn_best_params['hidden_dim']] * nn_best_params['n_layers']\n",
    "nn_best_params.pop('n_layers')\n",
    "nn_best_params.pop('hidden_dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nn_train = False\n",
    "epochs = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if nn_train == True:\n",
    "    learn_final = tabular_learner(dls_final, **nn_best_params, y_range=(0, 150), metrics=rmse)\n",
    "    learn_final.fit_one_cycle(epochs, nn_lr)\n",
    "    learn_final.export('models/tab_learner.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "learn_final = load_learner('models/tab_learner.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get NN Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "test_dl = learn_final.dls.test_dl(df_test)\n",
    "nn_preds, _ = learn_final.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nn_preds = nn_preds.squeeze().numpy()\n",
    "np.savetxt('./predictions/nn_preds.csv', nn_preds, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nn_preds = np.loadtxt('./predictions/nn_preds.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('./nn_submissions').mkdir(exist_ok=True, parents=True)\n",
    "sample_df = pd.read_csv(path/'sample_submission.csv')\n",
    "sample_df['cost'] = nn_preds\n",
    "sample_df.to_csv('./nn_submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub_nums = sample_df['cost'].to_numpy()\n",
    "benchmark_df = pd.read_csv('benchmark_submission.csv')\n",
    "benchmark_nums = benchmark_df['cost'].to_numpy()\n",
    "diffs = np.mean(np.abs(new_sub_nums - benchmark_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.484411156291848"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.13 / client 1.5.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.78M/5.78M [00:02<00:00, 2.24MB/s]\n"
     ]
    }
   ],
   "source": [
    "if not iskaggle and submit:\n",
    "    from kaggle import api\n",
    "    api.competition_submit_cli(file_name='./nn_submissions/submission.csv', message=\"nn_model\", competition=comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'nn_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_history = api.competitions_submissions_list(id=comp)\n",
    "submission_recent = [x for x in submission_history if x['description'] == current_model]\n",
    "most_recent_submission = max(submission_recent, key=lambda x: x['date'])\n",
    "if most_recent_submission['publicScore'] is not None:\n",
    "    current_model = most_recent_submission['description']\n",
    "    current_score = most_recent_submission['publicScore']\n",
    "\n",
    "    if not os.path.exists('model_scores.csv'):\n",
    "        with open('model_scores.csv', \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"model\", \"current_score\"])\n",
    "\n",
    "    model_score_df = pd.read_csv('./model_scores.csv')\n",
    "\n",
    "    if current_model in model_score_df['model'].values:\n",
    "        model_score_df.loc[model_score_df['model'] == current_model, 'current_score'] = current_score\n",
    "    else:\n",
    "        new_row = pd.DataFrame({\"model\": [current_model], \"current_score\": [current_score]})\n",
    "        model_score_df = pd.concat([model_score_df, new_row], ignore_index=True)\n",
    "        \n",
    "    pd.DataFrame(model_score_df).to_csv('./model_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.29889'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "nbdev.export.nb_export('nn_model.ipynb', 'nn_model')\n",
    "print(\"export successful\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:36:39) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4702a165a03ade35e40e0221d250a3a44a346cfc16a49ce6d051d1595069b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
